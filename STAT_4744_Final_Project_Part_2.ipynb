{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**INVERTED MNIST IMAGING**"
      ],
      "metadata": {
        "id": "ShF3cBulwM8Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HnUZrR-nOj6v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48819ea6-9d38-4bb1-cb09-03aa34f58c32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 15.0MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 406kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.79MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries.\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "import time\n",
        "from typing import Union, List, Dict, Any, cast\n",
        "from torch.nn import init\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "batch_size=64\n",
        "\n",
        "# Use the MODIFIED transform function with the lambda function to ensure images are being inverted.\n",
        "transform = transforms.Compose([transforms.Resize(224),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Lambda(lambda x: 1 - x),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "trainset = torchvision.datasets.MNIST(root=\"./data\",train=True, transform=transform, download=True)\n",
        "testset = torchvision.datasets.MNIST(root=\"./data\",train=False, transform=transform, download=True)\n",
        "trainloader = torch.utils.data.DataLoader(dataset=trainset,batch_size=batch_size,shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(dataset=testset,batch_size=batch_size,shuffle=False)\n",
        "\n",
        "# Define VGG structure.\n",
        "def vgg_block(num_convs, in_channels, num_channels):\n",
        "    layers=[]\n",
        "    for i in range(num_convs):\n",
        "        layers+=[nn.Conv2d(in_channels=in_channels, out_channels=num_channels, kernel_size=3, padding=1)]\n",
        "        in_channels=num_channels\n",
        "    layers +=[nn.BatchNorm2d(num_channels)]\n",
        "    layers +=[nn.ReLU()]\n",
        "    layers +=[nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "# Build the CNN.\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net,self).__init__()\n",
        "        self.conv_arch=((1,1,64),(1,64,128),(2,128,256),(2,256,512),(2,512,512))\n",
        "        layers=[]\n",
        "        for (num_convs,in_channels,num_channels) in self.conv_arch:\n",
        "            layers+=[vgg_block(num_convs,in_channels,num_channels)]\n",
        "        self.features=nn.Sequential(*layers)\n",
        "        self.dense1 = nn.Linear(512*7*7,4096)\n",
        "        self.drop1 = nn.Dropout(0.5)\n",
        "        self.dense2 = nn.Linear(4096, 4096)\n",
        "        self.drop2 = nn.Dropout(0.5)\n",
        "        self.dense3 = nn.Linear(4096, 10)\n",
        "\n",
        "    # Forward pass.\n",
        "    def forward(self,x):\n",
        "        x=self.features(x)\n",
        "        x=x.view(-1,512*7*7)\n",
        "        x=self.dense3(self.drop2(F.relu(self.dense2(self.drop1(F.relu(self.dense1(x)))))))\n",
        "        return x\n",
        "\n",
        "# Assess the accuracy of the function.\n",
        "def evaluate_accuracy(data_iter, net, device=None):\n",
        "    if device is None and isinstance(net, torch.nn.Module):\n",
        "        device = list(net.parameters())[0].device\n",
        "    acc_sum, n = 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in data_iter:\n",
        "            if isinstance(net, torch.nn.Module):\n",
        "                net.eval()\n",
        "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
        "                net.train()\n",
        "            else:\n",
        "                if ('is_training' in net.__code__.co_varnames):\n",
        "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item()\n",
        "                else:\n",
        "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
        "            n += y.shape[0]\n",
        "    return acc_sum / n\n",
        "\n",
        "# Define the training structure for the network.\n",
        "def train(train_iter, test_iter, net, optimizer, device, num_epochs):\n",
        "    net = net.to(device)\n",
        "    print(\"training on\", device)\n",
        "    loss = torch.nn.CrossEntropyLoss()\n",
        "    batch_count = 0\n",
        "    collaps = 0\n",
        "    simplex = torch.zeros(len(train_iter.dataset),10).to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
        "        for  X, y in tqdm(train_iter):\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            y_hat = net(X)\n",
        "            l = loss(y_hat, y)\n",
        "            optimizer.zero_grad()\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_l_sum += l.cpu().item()\n",
        "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
        "            n += y.shape[0]\n",
        "            batch_count += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model through 2 epochs.\n",
        "lr = 0.003\n",
        "num_epochs = 2\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "net1 = Net()\n",
        "optimizer = torch.optim.SGD(net1.parameters(), lr=0.001, momentum=0.9)\n",
        "train(trainloader, testloader, net1, optimizer, device, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1mdzV6ocfIN",
        "outputId": "2fe71ea7-36f7-4433-9b1c-df42ed41b6f7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training on cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [08:40<00:00,  1.80it/s]\n",
            "100%|██████████| 938/938 [08:42<00:00,  1.80it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate accuracy and print.\n",
        "test_acc = evaluate_accuracy(testloader, net1)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "id": "KXEnIb0scgcv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c9baab2-e7ae-41be-f9cb-49ed25833d6e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**UNMODIFIED MNIST IMAGING**"
      ],
      "metadata": {
        "id": "z7f9hgTYwPg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries.\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "import time\n",
        "from typing import Union, List, Dict, Any, cast\n",
        "from torch.nn import init\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size=64\n",
        "\n",
        "# Use the MODIFIED transform function WITHOUT LAMBDA FUNCTION.\n",
        "transform = transforms.Compose([transforms.Resize(224),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "trainset = torchvision.datasets.MNIST(root=\"./data\",train=True, transform=transform, download=True)\n",
        "testset = torchvision.datasets.MNIST(root=\"./data\",train=False, transform=transform, download=True)\n",
        "trainloader = torch.utils.data.DataLoader(dataset=trainset,batch_size=batch_size,shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(dataset=testset,batch_size=batch_size,shuffle=False)\n",
        "\n",
        "# Define VGG structure.\n",
        "def vgg_block(num_convs, in_channels, num_channels):\n",
        "    layers=[]\n",
        "    for i in range(num_convs):\n",
        "        layers+=[nn.Conv2d(in_channels=in_channels, out_channels=num_channels, kernel_size=3, padding=1)]\n",
        "        in_channels=num_channels\n",
        "    layers +=[nn.BatchNorm2d(num_channels)]\n",
        "    layers +=[nn.ReLU()]\n",
        "    layers +=[nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "# Builds the CNN.\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net,self).__init__()\n",
        "        self.conv_arch=((1,1,64),(1,64,128),(2,128,256),(2,256,512),(2,512,512))\n",
        "        layers=[]\n",
        "        for (num_convs,in_channels,num_channels) in self.conv_arch:\n",
        "            layers+=[vgg_block(num_convs,in_channels,num_channels)]\n",
        "        self.features=nn.Sequential(*layers)\n",
        "        self.dense1 = nn.Linear(512*7*7,4096)\n",
        "        self.drop1 = nn.Dropout(0.5)\n",
        "        self.dense2 = nn.Linear(4096, 4096)\n",
        "        self.drop2 = nn.Dropout(0.5)\n",
        "        self.dense3 = nn.Linear(4096, 10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.features(x)\n",
        "        x=x.view(-1,512*7*7)\n",
        "        x=self.dense3(self.drop2(F.relu(self.dense2(self.drop1(F.relu(self.dense1(x)))))))\n",
        "        return x\n",
        "\n",
        "# Assess the accuracy of the function.\n",
        "def evaluate_accuracy(data_iter, net, device=None):\n",
        "    if device is None and isinstance(net, torch.nn.Module):\n",
        "        device = list(net.parameters())[0].device\n",
        "    acc_sum, n = 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in data_iter:\n",
        "            if isinstance(net, torch.nn.Module):\n",
        "                net.eval()\n",
        "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
        "                net.train()\n",
        "            else:\n",
        "                if ('is_training' in net.__code__.co_varnames):\n",
        "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item()\n",
        "                else:\n",
        "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
        "            n += y.shape[0]\n",
        "    return acc_sum / n\n",
        "\n",
        "# Define the training structure for the network.\n",
        "def train(train_iter, test_iter, net, optimizer, device, num_epochs):\n",
        "    net = net.to(device)\n",
        "    print(\"training on\", device)\n",
        "    loss = torch.nn.CrossEntropyLoss()\n",
        "    batch_count = 0\n",
        "    collaps = 0\n",
        "    simplex = torch.zeros(len(train_iter.dataset),10).to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
        "        for  X, y in tqdm(train_iter):\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            y_hat = net(X)\n",
        "            l = loss(y_hat, y)\n",
        "            optimizer.zero_grad()\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_l_sum += l.cpu().item()\n",
        "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
        "            n += y.shape[0]\n",
        "            batch_count += 1"
      ],
      "metadata": {
        "id": "7JmuNNPHwWL7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model through 2 epochs.\n",
        "lr = 0.003\n",
        "num_epochs = 2\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "net1 = Net()\n",
        "optimizer = torch.optim.SGD(net1.parameters(), lr=0.001, momentum=0.9)\n",
        "train(trainloader, testloader, net1, optimizer, device, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3K3r0HwwYnR",
        "outputId": "45af10c4-fc40-46d0-db4b-419228398aea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training on cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [08:39<00:00,  1.80it/s]\n",
            "100%|██████████| 938/938 [08:38<00:00,  1.81it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate accuracy and print.\n",
        "test_acc = evaluate_accuracy(testloader, net1)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCFFoMViwaOz",
        "outputId": "13123972-0878-4221-dc47-299bab065538"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9897\n"
          ]
        }
      ]
    }
  ]
}